#python
import torch
import torchvision

# Digit classification network definition.
class Net(torch.nn.Module):
  def __init__(self, tamanho):
    super().__init__()
    self.tamanho = tamanho
    print("Criando uma rede de tamanho ", self.tamanho)
    self.encoder = torch.nn.Sequential(
      torch.nn.Conv2d(1, 6, 5),
      torch.nn.MaxPool2d(2, 2),
      torch.nn.ReLU(True),
      torch.nn.Conv2d(6, 16, 5),
      torch.nn.MaxPool2d(2, 2),
      torch.nn.ReLU(True)
    )
    self.classifier = torch.nn.Sequential(
      torch.nn.Linear(16 * 4 * 4, 120),
      torch.nn.ReLU(),
      torch.nn.Linear(120, self.tamanho),
      #torch.nn.ReLU(),
      #torch.nn.Linear(84, self.tamanho),
      torch.nn.Softmax(1)
    )

  def forward(self, x):
    print("Formato que a rede recebeu: ", x.shape, x.ndim)
    #print("Os dois primeiros elementos: ", x[:2][:10])
    x = self.encoder(x)
    x = x.view(-1, 16 * 4 * 4)
    x = self.classifier(x)
    print("Formato da resposta da rede: ", x.shape, x.ndim, x.dtype)
    return x

class Net2(torch.nn.Module):
  def __init__(self, tamanho):
    super().__init__()
    self.tamanho = tamanho
    print("Criando uma rede de tamanho ", self.tamanho)
    self.encoder = torch.nn.Sequential(
      torch.nn.Conv2d(1, 6, 5),
      torch.nn.MaxPool2d(2, 2),
      torch.nn.ReLU(True),
      torch.nn.Conv2d(6, 16, 5),
      torch.nn.MaxPool2d(2, 2),
      torch.nn.ReLU(True)
    )
    self.classifier = torch.nn.Sequential(
      torch.nn.Linear(16 * 4 * 4, 120),
      torch.nn.ReLU(),
      torch.nn.Linear(120, self.tamanho),
      #torch.nn.ReLU(),
      #torch.nn.Linear(84, self.tamanho),
      torch.nn.Softmax(1)
    )

  def forward(self, x):
    print("Formato que a rede recebeu: ", x.shape, x.ndim)
    #print("Os dois primeiros elementos: ", x[:2][:10])
    x = self.encoder(x)
    x = x.view(-1, 16 * 4 * 4)
    x = self.classifier(x)
    print("Formato da resposta da rede: ", x.shape, x.ndim, x.dtype)
    return x
# Return an instance of Net.
def digit_net_1(): return Net(10)
def digit_net_2(): return Net2(10)

# Retrieve the MNIST data.
def mnist_data():
  train = torchvision.datasets.MNIST(root = "/tmp", train = True, download = True)
  test  = torchvision.datasets.MNIST(root = "/tmp", train = False, download = True)
  return train.data.float().reshape(len(train), 1, 28, 28)/255., train.targets, \
         test.data.float().reshape(len(test), 1, 28, 28)/255., test.targets

# Normalization function to center pixel values around mu with standard deviation sigma.
def normalize(X_R, Y_R, X_T, Y_T, mu, sigma):
  return (X_R-mu)/sigma, Y_R, (X_T-mu)/sigma, Y_T

train_X, train_Y, test_X, test_Y = normalize(*mnist_data(), 0.1307, 0.3081)
train_X = train_X[:10]
train_Y = train_Y[:10]
test_X = test_X[:20]
test_Y = test_Y[:20]
print("Shape do train_X: ", train_X.shape)
print("Shape do train_Y: ", train_Y.shape)
print("Shape do test_X: ", test_X.shape)
print("Shape do test_Y: ", test_Y.shape)
# Whether to pick the first or second half of the dataset.
def pick_slice(data, which):
  h = len(data)//2
  return slice(h, len(data)) if which else slice(0, h)
# MNIST images for the train set.
def mnist_images_train(which):
  #resposta =  train_X[pick_slice(train_X, which)]
  resposta =  train_X
  print("No mnist_images_train, o tensor tem formato: ", resposta.shape)
  #print(resposta[0][:10])
  #print(resposta[1][:10])
  return resposta
# MNIST images for the test set.
def mnist_images_test(which):
  #resposta = test_X[pick_slice(test_X, which)]
  resposta = test_X
  print("No mnist_images_test, o tensor tem tamanho: ", resposta.shape) 
  return resposta
# Observed atoms for training.
def mnist_labels_train():
  # We join the two halves (top and bottom) of MNIST and join them together to get
  # two digits side by side. The labels are atoms encoding the sum of the two digits.
  labels = torch.concatenate((train_Y[:(h := len(train_Y)//2)].reshape(-1, 1),
                              train_Y[h:].reshape(-1, 1)), axis=1)
  #respostas = [[f"sum({x.item() + y.item()})"] for x, y in labels]
  respostas = []
  for x in train_Y:
     if x.item() >= 4:
       respostas.append([f"sum(4)"])
     else:
       respostas.append([f"sum({x.item()})"])
  #respostas = [[f"sum({x.item()*2})"] for x in train_Y]
  print("Os fatos observados: ", respostas)
  return respostas
#end.

% Data of the first digit.
input(0) ~ test(@mnist_images_test(0)), train(@mnist_images_train(0)).
% Data of the second digit.
%input(1) ~ test(@mnist_images_test(1)), train(@mnist_images_train(1)).

% Neural annotated disjunction over each digit from 0 to 9; use Adam as optimizer
% and a learning rate of 0.001.
?::digit2(X, {0..9}) as @digit_net_2 with optim = "Adam", lr = 0.001 :- input(X).
?::digit1(X, {0..9}) as @digit_net_1 with optim = "Adam", lr = 0.001 :- input(X).

% The sum.
%sum(Z) :- digit(0, X), digit(0, Y), Z = X+Y.
sum(Z) :- digit1(0, X), digit2(0, Y), Z = X+Y.
% Learn the parameters of the program from the "sum(X)" atoms.
#learn @mnist_labels_train, lr = 1., niters = 5, alg = "lagrange", batch = 4.
#semantics maxent.
% Ask for the probability of all groundings of sum(X).
#query sum(0).
#query sum(1).
#query sum(2).
#query sum(3).
#query sum(4).
#query sum(5).

